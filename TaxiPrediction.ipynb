{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohJrpEBPeo4W"
   },
   "source": [
    "# Business problem:\n",
    "\n",
    "Given pickup and dropoff locations, the pickup timestamp, and the passenger count, the objective is to predict the fare of the taxi ride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DlS_SvRft8T"
   },
   "source": [
    "## Features in Dataset\n",
    "<table>\n",
    "\t<tr>\n",
    "\t\t<th>Field Name</th>\n",
    "\t\t<th>Description</th>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>VendorID</td>\n",
    "\t\t<td>\n",
    "\t\tA code indicating the TPEP provider that provided the record.\n",
    "\t\t<ol>\n",
    "\t\t\t<li>Creative Mobile Technologies</li>\n",
    "\t\t\t<li>VeriFone Inc.</li>\n",
    "\t\t</ol>\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>tpep_pickup_datetime</td>\n",
    "\t\t<td>The date and time when the meter was engaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>tpep_dropoff_datetime</td>\n",
    "\t\t<td>The date and time when the meter was disengaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Passenger_count</td>\n",
    "\t\t<td>The number of passengers in the vehicle. This is a driver-entered value.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Trip_distance</td>\n",
    "\t\t<td>The elapsed trip distance in miles reported by the taximeter.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Pickup_longitude</td>\n",
    "\t\t<td>Longitude where the meter was engaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Pickup_latitude</td>\n",
    "\t\t<td>Latitude where the meter was engaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>RateCodeID</td>\n",
    "\t\t<td>The final rate code in effect at the end of the trip.\n",
    "\t\t<ol>\n",
    "\t\t\t<li> Standard rate </li>\n",
    "\t\t\t<li> JFK </li>\n",
    "\t\t\t<li> Newark </li>\n",
    "\t\t\t<li> Nassau or Westchester</li>\n",
    "\t\t\t<li> Negotiated fare </li>\n",
    "\t\t\t<li> Group ride</li>\n",
    "\t\t</ol>\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Store_and_fwd_flag</td>\n",
    "\t\t<td>This flag indicates whether the trip record was held in vehicle memory before sending to the vendor,<br\\> aka “store and forward,” because the vehicle did not have a connection to the server.\n",
    "\t\t<br\\>Y= store and forward trip\n",
    "\t\t<br\\>N= not a store and forward trip\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\n",
    "\t<tr>\n",
    "\t\t<td>Dropoff_longitude</td>\n",
    "\t\t<td>Longitude where the meter was disengaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Dropoff_ latitude</td>\n",
    "\t\t<td>Latitude where the meter was disengaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Payment_type</td>\n",
    "\t\t<td>A numeric code signifying how the passenger paid for the trip.\n",
    "\t\t<ol>\n",
    "\t\t\t<li> Credit card </li>\n",
    "\t\t\t<li> Cash </li>\n",
    "\t\t\t<li> No charge </li>\n",
    "\t\t\t<li> Dispute</li>\n",
    "\t\t\t<li> Unknown </li>\n",
    "\t\t\t<li> Voided trip</li>\n",
    "\t\t</ol>\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Fare_amount</td>\n",
    "\t\t<td>The time-and-distance fare calculated by the meter.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Extra</td>\n",
    "\t\t<td>Miscellaneous extras and surcharges. Currently, this only includes. the $0.50 and $1 rush hour and overnight charges.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>MTA_tax</td>\n",
    "\t\t<td>0.50 MTA tax that is automatically triggered based on the metered rate in use.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Improvement_surcharge</td>\n",
    "\t\t<td>0.30 improvement surcharge assessed trips at the flag drop. the improvement surcharge began being levied in 2015.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Tip_amount</td>\n",
    "\t\t<td>Tip amount – This field is automatically populated for credit card tips.Cash tips are not included.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Tolls_amount</td>\n",
    "\t\t<td>Total amount of all tolls paid in trip.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Total_amount</td>\n",
    "\t\t<td>The total amount charged to passengers. Does not include cash tips.</td>\n",
    "\t</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSb7plWan8OB"
   },
   "source": [
    "# Machine Learning Problem :\n",
    "\n",
    "As mentioned our goal is to predict the fare of taxi ride.Two important preprocessing tasks are involved:\n",
    "1. Binning data into 10 mins interval(Since the average time taken to travel 1 mile is 10 minutes in any of the region)\n",
    "2. Break NYC into clusters(regions)  \n",
    "It is a Time-Series forecasting and regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics :\n",
    "\n",
    "1. Mean Absolute percentage error(MAPE).  \n",
    "2. Mean Squared error(MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QuUj5-KftEC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'pickup_longitude',\n",
       "       'pickup_latitude', 'RateCodeID', 'store_and_fwd_flag',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount',\n",
       "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "       'improvement_surcharge', 'total_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "data_2015 = dd.read_csv(r'C:\\Users\\Friend\\AI\\AI_datasets\\Taxi_Prediction\\yellow_tripdata_2015-01.csv')\n",
    "data_2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12748986\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(data_2015))\n",
    "print(len(data_2015.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-15 19:05:39</td>\n",
       "      <td>2015-01-15 19:23:42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-73.993896</td>\n",
       "      <td>40.750111</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.974785</td>\n",
       "      <td>40.750618</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-10 20:33:38</td>\n",
       "      <td>2015-01-10 20:53:28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-74.001648</td>\n",
       "      <td>40.724243</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.994415</td>\n",
       "      <td>40.759109</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-10 20:33:38</td>\n",
       "      <td>2015-01-10 20:43:41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-73.963341</td>\n",
       "      <td>40.802788</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.951820</td>\n",
       "      <td>40.824413</td>\n",
       "      <td>2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-10 20:33:39</td>\n",
       "      <td>2015-01-10 20:35:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-74.009087</td>\n",
       "      <td>40.713818</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.004326</td>\n",
       "      <td>40.719986</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-10 20:33:39</td>\n",
       "      <td>2015-01-10 20:52:58</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-73.971176</td>\n",
       "      <td>40.762428</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.004181</td>\n",
       "      <td>40.742653</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2015-01-15 19:05:39   2015-01-15 19:23:42                1   \n",
       "1         1  2015-01-10 20:33:38   2015-01-10 20:53:28                1   \n",
       "2         1  2015-01-10 20:33:38   2015-01-10 20:43:41                1   \n",
       "3         1  2015-01-10 20:33:39   2015-01-10 20:35:31                1   \n",
       "4         1  2015-01-10 20:33:39   2015-01-10 20:52:58                1   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RateCodeID  \\\n",
       "0           1.59        -73.993896        40.750111           1   \n",
       "1           3.30        -74.001648        40.724243           1   \n",
       "2           1.80        -73.963341        40.802788           1   \n",
       "3           0.50        -74.009087        40.713818           1   \n",
       "4           3.00        -73.971176        40.762428           1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
       "0                  N         -73.974785         40.750618             1   \n",
       "1                  N         -73.994415         40.759109             1   \n",
       "2                  N         -73.951820         40.824413             2   \n",
       "3                  N         -74.004326         40.719986             2   \n",
       "4                  N         -74.004181         40.742653             2   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0         12.0    1.0      0.5        3.25           0.0   \n",
       "1         14.5    0.5      0.5        2.00           0.0   \n",
       "2          9.5    0.5      0.5        0.00           0.0   \n",
       "3          3.5    0.5      0.5        0.00           0.0   \n",
       "4         15.0    0.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3         17.05  \n",
       "1                    0.3         17.80  \n",
       "2                    0.3         10.80  \n",
       "3                    0.3          4.80  \n",
       "4                    0.3         16.30  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V07Qy9ZBBUQl"
   },
   "source": [
    "# Exploratory Data Analysis on features :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pickup_latitude & pickup_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247742"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of outliers(pickup_latitude & pickup_longitude)\n",
    "\n",
    "outlier_locations = data_2015[((data_2015.pickup_longitude <= -74.15) | (data_2015.pickup_latitude <= 40.5774)| \\\n",
    "                   (data_2015.pickup_longitude >= -73.7004) | (data_2015.pickup_latitude >= 40.9176))]\n",
    "\n",
    "\n",
    "len(outlier_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dropoff_latitude & dropoff_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pP5WlfSNDWkz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264440"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of outliers(dropoff_latitude & dropoff_longitude)\n",
    "\n",
    "outlier_locations = data_2015[((data_2015.dropoff_longitude <= -74.15) | (data_2015.dropoff_latitude <= 40.5774)| \\\n",
    "                   (data_2015.dropoff_longitude >= -73.7004) | (data_2015.dropoff_latitude >= 40.9176))]\n",
    "\n",
    "len(outlier_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* trip_times(tpep_pickup_datetime & tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AarcR9e7BRr1"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "def convert_to_unix(s):\n",
    "    return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "\n",
    "def return_with_trip_times(data_2015):\n",
    "    duration = data_2015[['tpep_pickup_datetime','tpep_dropoff_datetime']].compute()\n",
    "    duration_pickup = [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n",
    "    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n",
    "    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n",
    "    \n",
    "    new_frame = data_2015[['passenger_count','trip_distance','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','total_amount']].compute()\n",
    "    \n",
    "    new_frame['trip_times'] = durations\n",
    "    new_frame['pickup_times'] = duration_pickup\n",
    "    new_frame['Speed'] = 60*(new_frame['trip_distance']/new_frame['trip_times'])\n",
    "    \n",
    "    return new_frame\n",
    "\n",
    "\n",
    "frame_with_durations = return_with_trip_times(data_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is -1211.0166666666667\n",
      "10 percentile value is 3.8333333333333335\n",
      "20 percentile value is 5.383333333333334\n",
      "30 percentile value is 6.816666666666666\n",
      "40 percentile value is 8.3\n",
      "50 percentile value is 9.95\n",
      "60 percentile value is 11.866666666666667\n",
      "70 percentile value is 14.283333333333333\n",
      "80 percentile value is 17.633333333333333\n",
      "90 percentile value is 23.45\n",
      "100 percentile value is  548555.6333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,10):\n",
    "    var =frame_with_durations[\"trip_times\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print (\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 23.45\n",
      "91 percentile value is 24.35\n",
      "92 percentile value is 25.383333333333333\n",
      "93 percentile value is 26.55\n",
      "94 percentile value is 27.933333333333334\n",
      "95 percentile value is 29.583333333333332\n",
      "96 percentile value is 31.683333333333334\n",
      "97 percentile value is 34.46666666666667\n",
      "98 percentile value is 38.71666666666667\n",
      "99 percentile value is 46.75\n",
      "100 percentile value is  548555.6333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(90,100):\n",
    "    var =frame_with_durations[\"trip_times\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print (\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 percentile value is 46.75\n",
      "99.1 percentile value is 48.06666666666667\n",
      "99.2 percentile value is 49.56666666666667\n",
      "99.3 percentile value is 51.28333333333333\n",
      "99.4 percentile value is 53.31666666666667\n",
      "99.5 percentile value is 55.833333333333336\n",
      "99.6 percentile value is 59.13333333333333\n",
      "99.7 percentile value is 63.9\n",
      "99.8 percentile value is 71.86666666666666\n",
      "99.9 percentile value is 101.6\n",
      "100 percentile value is  548555.6333333333\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    var =frame_with_durations[\"trip_times\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,var[int(len(var)*(float(99+i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVEf6hknEuxj"
   },
   "outputs": [],
   "source": [
    "#Removal of Outlier(Trip time)\n",
    "\n",
    "frame_with_durations_modified = frame_with_durations[(frame_with_durations.trip_times>1) & (frame_with_durations.trip_times<720)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trip speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Friend\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "frame_with_durations_modified['Speed'] = 60*(frame_with_durations_modified['trip_distance']/frame_with_durations_modified['trip_times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 0.0\n",
      "10 percentile value is 6.409495548961425\n",
      "20 percentile value is 7.80952380952381\n",
      "30 percentile value is 8.929133858267717\n",
      "40 percentile value is 9.98019801980198\n",
      "50 percentile value is 11.06865671641791\n",
      "60 percentile value is 12.286689419795222\n",
      "70 percentile value is 13.796407185628745\n",
      "80 percentile value is 15.963224893917962\n",
      "90 percentile value is 20.186915887850468\n",
      "100 percentile value is  192857142.85714284\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,10):\n",
    "    var =frame_with_durations_modified[\"Speed\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 20.186915887850468\n",
      "91 percentile value is 20.91645569620253\n",
      "92 percentile value is 21.752988047808763\n",
      "93 percentile value is 22.721893491124263\n",
      "94 percentile value is 23.844155844155843\n",
      "95 percentile value is 25.182552504038775\n",
      "96 percentile value is 26.80851063829787\n",
      "97 percentile value is 28.84304932735426\n",
      "98 percentile value is 31.591128254580514\n",
      "99 percentile value is 35.7513566847558\n",
      "100 percentile value is  192857142.85714284\n"
     ]
    }
   ],
   "source": [
    "for i in range(90,100):\n",
    "    var =frame_with_durations_modified[\"Speed\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SK-LXKtACQZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 percentile value is 35.7513566847558\n",
      "99.1 percentile value is 36.31084727468969\n",
      "99.2 percentile value is 36.91470054446461\n",
      "99.3 percentile value is 37.588235294117645\n",
      "99.4 percentile value is 38.33035714285714\n",
      "99.5 percentile value is 39.17580340264651\n",
      "99.6 percentile value is 40.15384615384615\n",
      "99.7 percentile value is 41.338301043219076\n",
      "99.8 percentile value is 42.86631016042781\n",
      "99.9 percentile value is 45.3107822410148\n",
      "100 percentile value is  192857142.85714284\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    var =frame_with_durations_modified[\"Speed\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,var[int(len(var)*(float(99+i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofyYEAuUCnMm"
   },
   "outputs": [],
   "source": [
    "#Removal of Outlier(Trip Speed)\n",
    "\n",
    "frame_with_durations_modified=frame_with_durations[(frame_with_durations.Speed>0) & (frame_with_durations.Speed<44.37)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trip Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is 0.01\n",
      "10 percentile value is 0.66\n",
      "20 percentile value is 0.9\n",
      "30 percentile value is 1.1\n",
      "40 percentile value is 1.39\n",
      "50 percentile value is 1.69\n",
      "60 percentile value is 2.07\n",
      "70 percentile value is 2.6\n",
      "80 percentile value is 3.6\n",
      "90 percentile value is 5.94\n",
      "100 percentile value is  258.9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,10):\n",
    "    var =frame_with_durations_modified[\"trip_distance\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 5.94\n",
      "91 percentile value is 6.42\n",
      "92 percentile value is 7.04\n",
      "93 percentile value is 7.8\n",
      "94 percentile value is 8.7\n",
      "95 percentile value is 9.6\n",
      "96 percentile value is 10.59\n",
      "97 percentile value is 12.04\n",
      "98 percentile value is 15.96\n",
      "99 percentile value is 18.13\n",
      "100 percentile value is  258.9\n"
     ]
    }
   ],
   "source": [
    "for i in range(90,100):\n",
    "    var =frame_with_durations_modified[\"trip_distance\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhVffPoEDvWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 percentile value is 18.13\n",
      "99.1 percentile value is 18.33\n",
      "99.2 percentile value is 18.56\n",
      "99.3 percentile value is 18.8\n",
      "99.4 percentile value is 19.1\n",
      "99.5 percentile value is 19.49\n",
      "99.6 percentile value is 19.91\n",
      "99.7 percentile value is 20.5\n",
      "99.8 percentile value is 21.2\n",
      "99.9 percentile value is 22.5\n",
      "100 percentile value is  258.9\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    var =frame_with_durations_modified[\"trip_distance\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,var[int(len(var)*(float(99+i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uO-vUX3FH5l"
   },
   "outputs": [],
   "source": [
    "#Removal of Outlier(Trip distance)\n",
    "\n",
    "frame_with_durations_modified = frame_with_durations[(frame_with_durations.trip_distance>0) & (frame_with_durations.trip_distance<22.6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentile value is -242.55\n",
      "10 percentile value is 6.3\n",
      "20 percentile value is 7.8\n",
      "30 percentile value is 8.8\n",
      "40 percentile value is 9.8\n",
      "50 percentile value is 11.16\n",
      "60 percentile value is 12.8\n",
      "70 percentile value is 14.8\n",
      "80 percentile value is 18.3\n",
      "90 percentile value is 25.8\n",
      "100 percentile value is  3950611.6\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100,10):\n",
    "    var = frame_with_durations_modified[\"total_amount\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 percentile value is 25.8\n",
      "91 percentile value is 27.3\n",
      "92 percentile value is 29.16\n",
      "93 percentile value is 31.63\n",
      "94 percentile value is 34.8\n",
      "95 percentile value is 38.4\n",
      "96 percentile value is 42.42\n",
      "97 percentile value is 48.09\n",
      "98 percentile value is 58.13\n",
      "99 percentile value is 66.13\n",
      "100 percentile value is  3950611.6\n"
     ]
    }
   ],
   "source": [
    "for i in range(90,100):\n",
    "    var = frame_with_durations_modified[\"total_amount\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2_GlIcTFaFU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 percentile value is 66.13\n",
      "99.1 percentile value is 68.13\n",
      "99.2 percentile value is 69.6\n",
      "99.3 percentile value is 69.6\n",
      "99.4 percentile value is 69.73\n",
      "99.5 percentile value is 69.75\n",
      "99.6 percentile value is 69.76\n",
      "99.7 percentile value is 72.46\n",
      "99.8 percentile value is 75.33\n",
      "99.9 percentile value is 88.05\n",
      "100 percentile value is  3950611.6\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0, 1.0, 0.1):\n",
    "    var = frame_with_durations_modified[\"total_amount\"].values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print(\"{} percentile value is {}\".format(99+i,var[int(len(var)*(float(99+i)/100))]))\n",
    "print(\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.plot(var[-50:-2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIFgeqf-HSGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of data points that remain after removing outliers 0.9703576425607495\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(new_frame):\n",
    "    new_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n",
    "                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n",
    "                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n",
    "                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n",
    "    \n",
    "    new_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n",
    "    new_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n",
    "    new_frame = new_frame[(new_frame.Speed < 45.31) & (new_frame.Speed > 0)]\n",
    "    new_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n",
    "    return new_frame\n",
    "  \n",
    "frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n",
    "\n",
    "print(\"fraction of data points that remain after removing outliers\", float(len(frame_with_durations_outliers_removed))/len(frame_with_durations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXFxxjO1c8fL"
   },
   "source": [
    "# Clustering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0L0osRfdT2Q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On choosing a cluster size of  10 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 2.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 8.0 \n",
      "Min inter-cluster distance =  1.0945442325142543 \n",
      "---\n",
      "On choosing a cluster size of  20 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 4.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 16.0 \n",
      "Min inter-cluster distance =  0.7131298007387813 \n",
      "---\n",
      "On choosing a cluster size of  30 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 8.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 22.0 \n",
      "Min inter-cluster distance =  0.5185088176172206 \n",
      "---\n",
      "On choosing a cluster size of  40 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 8.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 32.0 \n",
      "Min inter-cluster distance =  0.5069768450363973 \n",
      "---\n",
      "On choosing a cluster size of  50 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 12.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 38.0 \n",
      "Min inter-cluster distance =  0.365363025983595 \n",
      "---\n",
      "On choosing a cluster size of  60 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 14.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 46.0 \n",
      "Min inter-cluster distance =  0.34704283494187155 \n",
      "---\n",
      "On choosing a cluster size of  70 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 16.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 54.0 \n",
      "Min inter-cluster distance =  0.30502203163244707 \n",
      "---\n",
      "On choosing a cluster size of  80 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 18.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 62.0 \n",
      "Min inter-cluster distance =  0.29220324531738534 \n",
      "---\n",
      "On choosing a cluster size of  90 \n",
      "Avg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2): 21.0 \n",
      "Avg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2): 69.0 \n",
      "Min inter-cluster distance =  0.18257992857034985 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import gpxpy.geo\n",
    "\n",
    "coords = frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']].values\n",
    "neighbours=[]\n",
    "\n",
    "def find_min_distance(cluster_centers, cluster_len):\n",
    "    nice_points = 0\n",
    "    wrong_points = 0\n",
    "    less2 = []\n",
    "    more2 = []\n",
    "    min_dist=1000\n",
    "    for i in range(0, cluster_len):\n",
    "        nice_points = 0\n",
    "        wrong_points = 0\n",
    "        for j in range(0, cluster_len):\n",
    "            if j!=i:\n",
    "                distance = gpxpy.geo.haversine_distance(cluster_centers[i][0], cluster_centers[i][1],cluster_centers[j][0], cluster_centers[j][1])\n",
    "                min_dist = min(min_dist,distance/(1.60934*1000))\n",
    "                if (distance/(1.60934*1000)) <= 2:\n",
    "                    nice_points +=1\n",
    "                else:\n",
    "                    wrong_points += 1\n",
    "        less2.append(nice_points)\n",
    "        more2.append(wrong_points)\n",
    "    neighbours.append(less2)\n",
    "    print (\"On choosing a cluster size of \",cluster_len,\"\\nAvg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2):\", np.ceil(sum(less2)/len(less2)), \"\\nAvg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2):\", np.ceil(sum(more2)/len(more2)),\"\\nMin inter-cluster distance = \",min_dist,\"\\n---\")\n",
    "\n",
    "def find_clusters(increment):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=increment, batch_size=10000,random_state=42).fit(coords)\n",
    "    frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    cluster_len = len(cluster_centers)\n",
    "    return cluster_centers, cluster_len\n",
    "\n",
    "for increment in range(10, 100, 10):\n",
    "    cluster_centers, cluster_len = find_clusters(increment)\n",
    "    find_min_distance(cluster_centers, cluster_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=40, batch_size=10000,random_state=0).fit(coords)\n",
    "frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_times</th>\n",
       "      <th>pickup_times</th>\n",
       "      <th>Speed</th>\n",
       "      <th>pickup_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-73.993896</td>\n",
       "      <td>40.750111</td>\n",
       "      <td>-73.974785</td>\n",
       "      <td>40.750618</td>\n",
       "      <td>17.05</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>1.421370e+09</td>\n",
       "      <td>5.285319</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-74.001648</td>\n",
       "      <td>40.724243</td>\n",
       "      <td>-73.994415</td>\n",
       "      <td>40.759109</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>9.983193</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-73.963341</td>\n",
       "      <td>40.802788</td>\n",
       "      <td>-73.951820</td>\n",
       "      <td>40.824413</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.050000</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>10.746269</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-74.009087</td>\n",
       "      <td>40.713818</td>\n",
       "      <td>-74.004326</td>\n",
       "      <td>40.719986</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>16.071429</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-73.971176</td>\n",
       "      <td>40.762428</td>\n",
       "      <td>-74.004181</td>\n",
       "      <td>40.742653</td>\n",
       "      <td>16.30</td>\n",
       "      <td>19.316667</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>9.318378</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1           1.59        -73.993896        40.750111   \n",
       "1                1           3.30        -74.001648        40.724243   \n",
       "2                1           1.80        -73.963341        40.802788   \n",
       "3                1           0.50        -74.009087        40.713818   \n",
       "4                1           3.00        -73.971176        40.762428   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  total_amount  trip_times  \\\n",
       "0         -73.974785         40.750618         17.05   18.050000   \n",
       "1         -73.994415         40.759109         17.80   19.833333   \n",
       "2         -73.951820         40.824413         10.80   10.050000   \n",
       "3         -74.004326         40.719986          4.80    1.866667   \n",
       "4         -74.004181         40.742653         16.30   19.316667   \n",
       "\n",
       "   pickup_times      Speed  pickup_cluster  \n",
       "0  1.421370e+09   5.285319              34  \n",
       "1  1.420944e+09   9.983193               2  \n",
       "2  1.420944e+09  10.746269              16  \n",
       "3  1.420944e+09  16.071429              38  \n",
       "4  1.420944e+09   9.318378              22  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_with_durations_outliers_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pickup_bins(frame,data_2015,year):\n",
    "    unix_pickup_times=[i for i in frame['pickup_times'].values]\n",
    "    unix_times = [[1420070400,1422748800,1425168000,1427846400,1430438400,1433116800],\\\n",
    "                    [1451606400,1454284800,1456790400,1459468800,1462060800,1464739200]]\n",
    "    \n",
    "    start_pickup_unix=unix_times[year-2015][data_2015-1]\n",
    "    tenminutewise_binned_unix_pickup_times=[(int((i-start_pickup_unix)/600)+33) for i in unix_pickup_times]\n",
    "    frame['pickup_bins'] = np.array(tenminutewise_binned_unix_pickup_times)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_times</th>\n",
       "      <th>pickup_times</th>\n",
       "      <th>Speed</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>pickup_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-73.993896</td>\n",
       "      <td>40.750111</td>\n",
       "      <td>-73.974785</td>\n",
       "      <td>40.750618</td>\n",
       "      <td>17.05</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>1.421370e+09</td>\n",
       "      <td>5.285319</td>\n",
       "      <td>34</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-74.001648</td>\n",
       "      <td>40.724243</td>\n",
       "      <td>-73.994415</td>\n",
       "      <td>40.759109</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>9.983193</td>\n",
       "      <td>2</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-73.963341</td>\n",
       "      <td>40.802788</td>\n",
       "      <td>-73.951820</td>\n",
       "      <td>40.824413</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.050000</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>10.746269</td>\n",
       "      <td>16</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-74.009087</td>\n",
       "      <td>40.713818</td>\n",
       "      <td>-74.004326</td>\n",
       "      <td>40.719986</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>16.071429</td>\n",
       "      <td>38</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-73.971176</td>\n",
       "      <td>40.762428</td>\n",
       "      <td>-74.004181</td>\n",
       "      <td>40.742653</td>\n",
       "      <td>16.30</td>\n",
       "      <td>19.316667</td>\n",
       "      <td>1.420944e+09</td>\n",
       "      <td>9.318378</td>\n",
       "      <td>22</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1           1.59        -73.993896        40.750111   \n",
       "1                1           3.30        -74.001648        40.724243   \n",
       "2                1           1.80        -73.963341        40.802788   \n",
       "3                1           0.50        -74.009087        40.713818   \n",
       "4                1           3.00        -73.971176        40.762428   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  total_amount  trip_times  \\\n",
       "0         -73.974785         40.750618         17.05   18.050000   \n",
       "1         -73.994415         40.759109         17.80   19.833333   \n",
       "2         -73.951820         40.824413         10.80   10.050000   \n",
       "3         -74.004326         40.719986          4.80    1.866667   \n",
       "4         -74.004181         40.742653         16.30   19.316667   \n",
       "\n",
       "   pickup_times      Speed  pickup_cluster  pickup_bins  \n",
       "0  1.421370e+09   5.285319              34         2199  \n",
       "1  1.420944e+09   9.983193               2         1488  \n",
       "2  1.420944e+09  10.746269              16         1488  \n",
       "3  1.420944e+09  16.071429              38         1488  \n",
       "4  1.420944e+09   9.318378              22         1488  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_2015_frame = add_pickup_bins(frame_with_durations_outliers_removed,1,2015)\n",
    "jan_2015_groupby = jan_2015_frame[['pickup_cluster','pickup_bins','trip_distance']].groupby(['pickup_cluster','pickup_bins']).count()\n",
    "jan_2015_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>pickup_bins</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>69</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            trip_distance\n",
       "pickup_cluster pickup_bins               \n",
       "0              69                     104\n",
       "               70                     200\n",
       "               71                     208\n",
       "               72                     141\n",
       "               73                     155"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_2015_groupby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_unq_pickup_bins(frame):\n",
    "    values = []\n",
    "    for i in range(0,40):\n",
    "        new = frame[frame['pickup_cluster'] == i]\n",
    "        list_unq = list(set(new['pickup_bins']))\n",
    "        list_unq.sort()\n",
    "        values.append(list_unq)\n",
    "    return values\n",
    "\n",
    "jan_2015_unique = return_unq_pickup_bins(jan_2015_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def fill_missing(count_values,values):\n",
    "    smoothed_regions=[]\n",
    "    ind=0\n",
    "    for r in range(0,40):\n",
    "        smoothed_bins=[]\n",
    "        for i in range(4464):\n",
    "            if i in values[r]:\n",
    "                smoothed_bins.append(count_values[ind])\n",
    "                ind+=1\n",
    "            else:\n",
    "                smoothed_bins.append(0)\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions\n",
    "\n",
    "def smoothing(count_values,values):\n",
    "    smoothed_regions=[] # stores list of final smoothed values of each reigion\n",
    "    ind=0\n",
    "    repeat=0 \n",
    "    smoothed_value=0\n",
    "    for r in range(0,40):\n",
    "        smoothed_bins=[] #stores the final smoothed values\n",
    "        repeat=0\n",
    "        for i in range(4464):\n",
    "            if repeat!=0: # prevents iteration for a value which is already visited/resolved\n",
    "                repeat-=1\n",
    "                continue\n",
    "            if i in values[r]: #checks if the pickup-bin exists \n",
    "                smoothed_bins.append(count_values[ind]) # appends the value of the pickup bin if it exists\n",
    "            else:\n",
    "                if i!=0:\n",
    "                    right_hand_limit=0\n",
    "                    for j in range(i,4464):\n",
    "                        if  j not in values[r]: #searches for the left-limit or the pickup-bin value which has a pickup value\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit=j\n",
    "                            break\n",
    "                    if right_hand_limit==0:\n",
    "                    #Case 1: When we have the last/last few values are found to be missing,hence we have no right-limit here\n",
    "                        smoothed_value=count_values[ind-1]*1.0/((4463-i)+2)*1.0                               \n",
    "                        for j in range(i,4464):                              \n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat=(4463-i)\n",
    "                        ind-=1\n",
    "                    else:\n",
    "                    #Case 2: When we have the missing values between two known values\n",
    "                        smoothed_value=(count_values[ind-1]+count_values[ind])*1.0/((right_hand_limit-i)+2)*1.0             \n",
    "                        \n",
    "                        for j in range(i,right_hand_limit+1):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat=(right_hand_limit-i)\n",
    "                else:\n",
    "                    #Case 3: When we have the first/first few values are found to be missing,hence we have no left-limit here\n",
    "                    right_hand_limit=0\n",
    "                    for j in range(i,4464):\n",
    "                        if  j not in values[r]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit=j\n",
    "                            break\n",
    "                    smoothed_value=count_values[ind]*1.0/((right_hand_limit-i)+1)*1.0\n",
    "                    for j in range(i,right_hand_limit+1):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                    repeat=(right_hand_limit-i)\n",
    "            ind+=1\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2015_fill = fill_missing(jan_2015_groupby['trip_distance'].values,jan_2015_unique)\n",
    "jan_2015_smooth = smoothing(jan_2015_groupby['trip_distance'].values,jan_2015_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178560"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jan_2015_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreparation(data_2015,kmeans,month_no,year_no):\n",
    "    frame_with_durations = return_with_trip_times(data_2015)\n",
    "    frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n",
    "    frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "    final_updated_frame = add_pickup_bins(frame_with_durations_outliers_removed,month_no,year_no)\n",
    "    final_groupby_frame = final_updated_frame[['pickup_cluster','pickup_bins','trip_distance']].groupby(['pickup_cluster','pickup_bins']).count()\n",
    "    \n",
    "    return final_updated_frame,final_groupby_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_jan_2016 = dd.read_csv(r'C:\\Users\\Friend\\AI\\AI_datasets\\Taxi_Prediction\\yellow_tripdata_2016-01.csv')\n",
    "jan_2016_frame,jan_2016_groupby = datapreparation(month_jan_2016,kmeans,1,2016)\n",
    "jan_2016_unique = return_unq_pickup_bins(jan_2016_frame)\n",
    "jan_2016_smooth = fill_missing(jan_2016_groupby['trip_distance'].values,jan_2016_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_feb_2016 = dd.read_csv(r'C:\\Users\\Friend\\AI\\AI_datasets\\Taxi_Prediction\\yellow_tripdata_2016-02.csv')\n",
    "feb_2016_frame,feb_2016_groupby = datapreparation(month_feb_2016,kmeans,2,2016)\n",
    "feb_2016_unique = return_unq_pickup_bins(feb_2016_frame)\n",
    "feb_2016_smooth = fill_missing(feb_2016_groupby['trip_distance'].values,feb_2016_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mar_2016 = dd.read_csv(r'C:\\Users\\Friend\\AI\\AI_datasets\\Taxi_Prediction\\yellow_tripdata_2016-03.csv')\n",
    "mar_2016_frame,mar_2016_groupby = datapreparation(month_mar_2016,kmeans,3,2016)\n",
    "mar_2016_unique = return_unq_pickup_bins(mar_2016_frame)\n",
    "mar_2016_smooth = fill_missing(mar_2016_groupby['trip_distance'].values,mar_2016_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_jan = pd.DataFrame()\n",
    "ratios_jan['Given']=jan_2015_smooth\n",
    "ratios_jan['Prediction']=jan_2016_smooth\n",
    "ratios_jan['Ratios']=ratios_jan['Prediction']*1.0/ratios_jan['Given']*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178560, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios_jan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EA_R1_Predictions(ratios,data_2015):\n",
    "    predicted_ratio=(ratios['Ratios'].values)[0]\n",
    "    alpha=0.6\n",
    "    error=[]\n",
    "    predicted_values=[]\n",
    "    predicted_ratio_values=[]\n",
    "    for i in range(0,4464*40):\n",
    "        if i%4464==0:\n",
    "            predicted_ratio_values.append(0)\n",
    "            predicted_values.append(0)\n",
    "            error.append(0)\n",
    "            continue\n",
    "        predicted_ratio_values.append(predicted_ratio)\n",
    "        predicted_values.append(int(((ratios['Given'].values)[i])*predicted_ratio))\n",
    "        error.append(abs((math.pow(int(((ratios['Given'].values)[i])*predicted_ratio)-(ratios['Prediction'].values)[i],1))))\n",
    "        predicted_ratio = (alpha*predicted_ratio) + (1-alpha)*((ratios['Ratios'].values)[i])\n",
    "    \n",
    "    ratios['EA_R1_Predicted'] = predicted_values\n",
    "    ratios['EA_R1_Error'] = error\n",
    "    mape_err = (sum(error)/len(error))/(sum(ratios['Prediction'].values)/len(ratios['Prediction'].values))\n",
    "    mse_err = sum([e**2 for e in error])/len(error)\n",
    "    return ratios,mape_err,mse_err\n",
    "\n",
    "def EA_P1_Predictions(ratios,data_2015):\n",
    "    predicted_value= (ratios['Prediction'].values)[0]\n",
    "    alpha=0.3\n",
    "    error=[]\n",
    "    predicted_values=[]\n",
    "    for i in range(0,4464*40):\n",
    "        if i%4464==0:\n",
    "            predicted_values.append(0)\n",
    "            error.append(0)\n",
    "            continue\n",
    "        predicted_values.append(predicted_value)\n",
    "        error.append(abs((math.pow(predicted_value-(ratios['Prediction'].values)[i],1))))\n",
    "        predicted_value =int((alpha*predicted_value) + (1-alpha)*((ratios['Prediction'].values)[i]))\n",
    "    \n",
    "    ratios['EA_P1_Predicted'] = predicted_values\n",
    "    ratios['EA_P1_Error'] = error\n",
    "    mape_err = (sum(error)/len(error))/(sum(ratios['Prediction'].values)/len(ratios['Prediction'].values))\n",
    "    mse_err = sum([e**2 for e in error])/len(error)\n",
    "    return ratios,mape_err,mse_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_err=[0]*2\n",
    "median_err=[0]*2\n",
    "\n",
    "ratios_jan,mean_err[0],median_err[0]=EA_R1_Predictions(ratios_jan,'jan')\n",
    "ratios_jan,mean_err[1],median_err[1]=EA_P1_Predictions(ratios_jan,'jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2801125176779463, 0.15716114877006163]\n"
     ]
    }
   ],
   "source": [
    "print(mean_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_cum = []\n",
    "\n",
    "for i in range(0,40):\n",
    "    regions_cum.append(jan_2016_smooth[4464*i:4464*(i+1)]+feb_2016_smooth[4176*i:4176*(i+1)]+mar_2016_smooth[4464*i:4464*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_time_stamps = 5\n",
    "output = []\n",
    "tsne_lat = []\n",
    "tsne_lon = []\n",
    "tsne_weekday = []\n",
    "tsne_feature = []\n",
    "\n",
    "tsne_feature = [0]*number_of_time_stamps\n",
    "for i in range(0,40):\n",
    "    tsne_lat.append([kmeans.cluster_centers_[i][0]]*13099)\n",
    "    tsne_lon.append([kmeans.cluster_centers_[i][1]]*13099)\n",
    "    # jan 1st 2016 is thursday, so we start our day from 4: \"(int(k/144))%7+4\"\n",
    "    # our prediction start from 5th 10min intravel since we need to have number of pickups that are happened in last 5 pickup bins\n",
    "    tsne_weekday.append([int(((int(k/144))%7+4)%7) for k in range(5,4464+4176+4464)])\n",
    "    # regions_cum is a list of lists [[x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], .. 40 lsits]\n",
    "    tsne_feature = np.vstack((tsne_feature, [regions_cum[i][r:r+number_of_time_stamps] for r in range(0,len(regions_cum[i])-number_of_time_stamps)]))\n",
    "    output.append(regions_cum[i][5:])\n",
    "tsne_feature = tsne_feature[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform as Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampli_fourier = []\n",
    "freq_fourier = []\n",
    "for i in range(40):\n",
    "    ampli  = np.abs(np.fft.fft(regions_cum[i]))\n",
    "    freq = np.abs(np.fft.fftfreq(13104, 1))\n",
    "    ampli_indices = np.argsort(-ampli)[1:]\n",
    "    amplitude = []\n",
    "    frequency = []\n",
    "    for j in range(0,5,1):\n",
    "        amplitude.append(ampli[ampli_indices[j]])\n",
    "        frequency.append(freq[ampli_indices[j]])\n",
    "    for k in range(13099):\n",
    "        ampli_fourier.append(amplitude)\n",
    "        freq_fourier.append(frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[352892.24492958514,\n",
       " 352892.24492958514,\n",
       " 189333.3058368882,\n",
       " 189333.3058368882,\n",
       " 80556.42829136703]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ampli_fourier[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.3\n",
    "predicted_values=[]\n",
    "\n",
    "predict_list = []\n",
    "tsne_flat_exp_avg = []\n",
    "for r in range(0,40):\n",
    "    for i in range(0,13104):\n",
    "        if i==0:\n",
    "            predicted_value= regions_cum[r][0]\n",
    "            predicted_values.append(0)\n",
    "            continue\n",
    "        predicted_values.append(predicted_value)\n",
    "        predicted_value =int((alpha*predicted_value) + (1-alpha)*(regions_cum[r][i]))\n",
    "    predict_list.append(predicted_values[5:])\n",
    "    predicted_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features =  [tsne_feature[i*13099:(13099*i+9169)] for i in range(0,40)]\n",
    "test_features = [tsne_feature[(13099*(i))+9169:13099*(i+1)] for i in range(0,40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fourier_frequencies = [freq_fourier[i*13099:(13099*i+9169)] for i in range(40)]\n",
    "test_fourier_frequencies = [freq_fourier[(13099*(i))+9169:13099*(i+1)] for i in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fourier_amplitudes = [ampli_fourier[i*13099:(13099*i+9169)] for i in range(40)]\n",
    "test_fourier_amplitudes = [ampli_fourier[(13099*(i))+9169:13099*(i+1)] for i in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_train_flat_lat = [i[:9169] for i in tsne_lat]\n",
    "tsne_train_flat_lon = [i[:9169] for i in tsne_lon]\n",
    "tsne_train_flat_weekday = [i[:9169] for i in tsne_weekday]\n",
    "tsne_train_flat_output = [i[:9169] for i in output]\n",
    "tsne_train_flat_exp_avg = [i[:9169] for i in predict_list]\n",
    "\n",
    "tsne_test_flat_lat = [i[9169:] for i in tsne_lat]\n",
    "tsne_test_flat_lon = [i[9169:] for i in tsne_lon]\n",
    "tsne_test_flat_weekday = [i[9169:] for i in tsne_weekday]\n",
    "tsne_test_flat_output = [i[9169:] for i in output]\n",
    "tsne_test_flat_exp_avg = [i[9169:] for i in predict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_features = []\n",
    "for i in range(0,40):\n",
    "    train_new_features.extend(train_features[i])\n",
    "test_new_features = []\n",
    "for i in range(0,40):\n",
    "    test_new_features.extend(test_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_freq = []\n",
    "for i in range(0,40):\n",
    "    train_freq.extend(train_fourier_frequencies[i])\n",
    "test_freq = []\n",
    "for i in range(0,40):\n",
    "    test_freq.extend(train_fourier_frequencies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amp = []\n",
    "for i in range(0,40):\n",
    "    train_amp.extend(train_fourier_amplitudes[i])\n",
    "test_amp = []\n",
    "for i in range(0,40):\n",
    "    test_amp.extend(test_fourier_amplitudes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_train_lat = sum(tsne_train_flat_lat, [])\n",
    "tsne_train_lon = sum(tsne_train_flat_lon, [])\n",
    "tsne_train_weekday = sum(tsne_train_flat_weekday, [])\n",
    "tsne_train_output = sum(tsne_train_flat_output, [])\n",
    "tsne_train_exp_avg = sum(tsne_train_flat_exp_avg,[])\n",
    "\n",
    "tsne_test_lat = sum(tsne_test_flat_lat, [])\n",
    "tsne_test_lon = sum(tsne_test_flat_lon, [])\n",
    "tsne_test_weekday = sum(tsne_test_flat_weekday, [])\n",
    "tsne_test_output = sum(tsne_test_flat_output, [])\n",
    "tsne_test_exp_avg = sum(tsne_test_flat_exp_avg,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366760, 5)\n",
      "(157200, 5)\n"
     ]
    }
   ],
   "source": [
    "columns = ['amp1','amp2','amp3','amp4','amp5']\n",
    "amp_train = pd.DataFrame(data=train_amp, columns=columns)\n",
    "print(amp_train.shape)\n",
    "\n",
    "columns = ['amp1','amp2','amp3','amp4','amp5']\n",
    "amp_test = pd.DataFrame(data=test_amp, columns=columns)\n",
    "print(amp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366760, 5)\n",
      "(366760, 5)\n"
     ]
    }
   ],
   "source": [
    "columns = ['freq1','freq2','freq3','freq4','freq5']\n",
    "freq_train = pd.DataFrame(data=train_freq, columns=columns)\n",
    "print(freq_train.shape)\n",
    "\n",
    "columns = ['freq1','freq2','freq3','freq4','freq5']\n",
    "freq_test = pd.DataFrame(data=test_freq, columns=columns)\n",
    "print(freq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366760, 9)\n",
      "(157200, 9)\n"
     ]
    }
   ],
   "source": [
    "columns = ['ft_5','ft_4','ft_3','ft_2','ft_1']\n",
    "df_train = pd.DataFrame(data=train_new_features, columns=columns) \n",
    "df_train['lat'] = tsne_train_lat\n",
    "df_train['lon'] = tsne_train_lon\n",
    "df_train['weekday'] = tsne_train_weekday\n",
    "df_train['exp_avg'] = tsne_train_exp_avg\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.DataFrame(data=test_new_features, columns=columns) \n",
    "df_test['lat'] = tsne_test_lat\n",
    "df_test['lon'] = tsne_test_lon\n",
    "df_test['weekday'] = tsne_test_weekday\n",
    "df_test['exp_avg'] = tsne_test_exp_avg\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366760, 19)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.join(freq_train)\n",
    "df_train = df_train.join(amp_train)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>amp3</th>\n",
       "      <th>amp4</th>\n",
       "      <th>amp5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366755</th>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>128</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366756</th>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>128</td>\n",
       "      <td>94</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366757</th>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>128</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366758</th>\n",
       "      <td>87</td>\n",
       "      <td>128</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366759</th>\n",
       "      <td>128</td>\n",
       "      <td>94</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ft_5  ft_4  ft_3  ft_2  ft_1        lat        lon  weekday  exp_avg  \\\n",
       "366755    67    64    85    87   128  40.734208 -73.993977        4      114   \n",
       "366756    64    85    87   128    94  40.734208 -73.993977        4      100   \n",
       "366757    85    87   128    94    82  40.734208 -73.993977        4       87   \n",
       "366758    87   128    94    82    85  40.734208 -73.993977        4       85   \n",
       "366759   128    94    82    85    78  40.734208 -73.993977        4       80   \n",
       "\n",
       "           freq1     freq2     freq3     freq4     freq5           amp1  \\\n",
       "366755  0.000153  0.000153  0.006868  0.006868  0.000076  121351.934522   \n",
       "366756  0.000153  0.000153  0.006868  0.006868  0.000076  121351.934522   \n",
       "366757  0.000153  0.000153  0.006868  0.006868  0.000076  121351.934522   \n",
       "366758  0.000153  0.000153  0.006868  0.006868  0.000076  121351.934522   \n",
       "366759  0.000153  0.000153  0.006868  0.006868  0.000076  121351.934522   \n",
       "\n",
       "                 amp2         amp3         amp4          amp5  \n",
       "366755  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "366756  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "366757  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "366758  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "366759  121351.934522  98076.01479  98076.01479  92844.540973  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157200, 19)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.join(freq_test)\n",
    "df_test = df_test.join(amp_test)\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>amp3</th>\n",
       "      <th>amp4</th>\n",
       "      <th>amp5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157195</th>\n",
       "      <td>77</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157196</th>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157197</th>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157198</th>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157199</th>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>40.734208</td>\n",
       "      <td>-73.993977</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>121351.934522</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>98076.01479</td>\n",
       "      <td>92844.540973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ft_5  ft_4  ft_3  ft_2  ft_1        lat        lon  weekday  exp_avg  \\\n",
       "157195    77    85    81    92    77  40.734208 -73.993977        3       80   \n",
       "157196    85    81    92    77    97  40.734208 -73.993977        3       91   \n",
       "157197    81    92    77    97    79  40.734208 -73.993977        3       82   \n",
       "157198    92    77    97    79    92  40.734208 -73.993977        3       88   \n",
       "157199    77    97    79    92    83  40.734208 -73.993977        3       84   \n",
       "\n",
       "           freq1     freq2     freq3     freq4     freq5           amp1  \\\n",
       "157195  0.006944  0.006944  0.000076  0.000076  0.013889  121351.934522   \n",
       "157196  0.006944  0.006944  0.000076  0.000076  0.013889  121351.934522   \n",
       "157197  0.006944  0.006944  0.000076  0.000076  0.013889  121351.934522   \n",
       "157198  0.006944  0.006944  0.000076  0.000076  0.013889  121351.934522   \n",
       "157199  0.006944  0.006944  0.000076  0.000076  0.013889  121351.934522   \n",
       "\n",
       "                 amp2         amp3         amp4          amp5  \n",
       "157195  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "157196  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "157197  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "157198  121351.934522  98076.01479  98076.01479  92844.540973  \n",
       "157199  121351.934522  98076.01479  98076.01479  92844.540973  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "Grid_Parameters = {'alpha' : [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "clf_linear = GridSearchCV(SGDRegressor(loss = \"squared_loss\", penalty = \"l2\"),Grid_Parameters,cv =5)\n",
    "clf_linear.fit(df_train, tsne_train_output)\n",
    "alpha = clf_linear.best_params_[\"alpha\"]\n",
    "\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = SGDRegressor(loss = \"squared_loss\", penalty = \"l2\", alpha = alpha)\n",
    "clf_linear.fit(df_train, tsne_train_output)\n",
    "\n",
    "train_y_pred = clf_linear.predict(df_train)\n",
    "test_y_pred = clf_linear.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_linear = mean_absolute_error(tsne_train_output, train_y_pred)/(sum(tsne_train_output)/len(tsne_train_output))\n",
    "test_error_linear = mean_absolute_error(tsne_test_output, test_y_pred)/(sum(tsne_test_output)/len(tsne_test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_hyperparameter = [{'n_estimators'  : [50,100,1000,2000],'max_depth':[5,10]}]\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(max_features='sqrt',min_samples_leaf=4,min_samples_split=3), grid_hyperparameter, cv=2)\n",
    "clf.fit(df_train, tsne_train_output)\n",
    "\n",
    "clf_n = clf.best_estimator_.get_params()['n_estimators']\n",
    "clf_depth = clf.best_estimator_.get_params()['max_depth']\n",
    "\n",
    "print(clf_n,clf_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestRegressor(max_features='sqrt',min_samples_leaf=4,min_samples_split=3,n_estimators=clf_n,max_depth = clf_depth)\n",
    "clf_RF.fit(df_train, tsne_train_output)\n",
    "\n",
    "train_y_pred = clf_RF.predict(df_train)\n",
    "test_y_pred = clf_RF.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_RF = mean_absolute_error(tsne_train_output,train_y_pred)/(sum(tsne_train_output)/len(tsne_train_output))\n",
    "test_error_RF = mean_absolute_error(tsne_test_output, test_y_pred)/(sum(tsne_test_output)/len(tsne_test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "grid_hyperparameter = [{'n_estimators'  : [50,100,1000,2000],'max_depth':[5,10]}]\n",
    "\n",
    "x_model = xgb.XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=3,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " reg_alpha=200, reg_lambda=200,\n",
    " colsample_bytree=0.8,nthread=4)\n",
    "\n",
    "clf_XG = GridSearchCV(x_model, grid_hyperparameter, cv=2)\n",
    "clf_XG.fit(df_train, tsne_train_output)\n",
    "\n",
    "clf_n = clf_XG.best_estimator_.get_params()['n_estimators']\n",
    "clf_depth = clf_XG.best_estimator_.get_params()['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_XG =  xgb.XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=clf_n,\n",
    " max_depth=clf_depth,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " reg_alpha=200, reg_lambda=200,\n",
    " colsample_bytree=0.8,nthread=4)\n",
    "regr1.fit(df_train, tsne_train_output)\n",
    "\n",
    "train_y_pred = clf_XG.predict(df_train)\n",
    "test_y_pred = clf_XG.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_xg = mean_absolute_error(tsne_train_output,train_y_pred)/(sum(tsne_train_output)/len(tsne_train_output))\n",
    "test_error_xg = mean_absolute_error(tsne_test_output, test_y_pred)/(sum(tsne_test_output)/len(tsne_test_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+----------------+\n",
      "|       Model       |   Train error   |   Test error   |\n",
      "+-------------------+-----------------+----------------+\n",
      "| Linear Regression |  0.113648123791 | 0.129361804204 |\n",
      "|   Random Forest   | 0.0717619563182 | 0.124542461769 |\n",
      "|      XGBoost      |  0.119387790351 | 0.115742475694 |\n",
      "+-------------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "Table = PrettyTable()\n",
    "\n",
    "Table.field_names  = [\"Model\",\"Train error\", \"Test error\"]\n",
    "\n",
    "Table.add_row([\"Linear Regression\", train_error_linear,test_error_linear])\n",
    "Table.add_row([\"Random Forest\",train_error_RF, test_error_RF])\n",
    "Table.add_row([\"XGBoost\",train_error_xg,test_error_xg])\n",
    "\n",
    "print(Table)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TaxiPrediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
